import gspread
from oauth2client.service_account import ServiceAccountCredentials
from typing import List, Dict, Any
from urllib.parse import urlparse, parse_qs
from typing import Optional
from avito import fetch_and_process_items
from auto import parse_auto
from avito_id import get_avito_links_with_seller_id
import asyncio
import time
import re
from logg import get_logger

logger = get_logger(__name__)


# –ê–≤—Ç–æ—Ä–∏–∑–∞—Ü–∏—è —á–µ—Ä–µ–∑ —Å–ª–æ–≤–∞—Ä—å credentials
CREDENTIALS_DICT = {
    "type": "service_account",
    "project_id": "excelproject-455714",
    "private_key_id": "91bee9e13a81b39e2fed4a8d0247495d889005b4",
    "private_key": "-----BEGIN PRIVATE KEY-----\nMIIEvgIBADANBgkqhkiG9w0BAQEFAASCBKgwggSkAgEAAoIBAQCSmZKio6dVZCD/\n3zMg0JipTmiCQY/VoJo4BAjLgTGMnJVCqB7w4sYBr+Qcb+XFQ77+RLVtFKeTnFG1\n5JDYNZvvIgWNg+vl6JiXeBrGjihpykMQqROXTttJ5Dk38VZ3PpMyEE6miivFDuZC\nB+8AcJUsIr15i3Vv0TaW13lF0R+2PVaRffFlKDS+NLkG5LKfsY8r+jbN8FiVbdLR\nmxzdT2OROewYxEJcvZn/4EywmMsLCrXb1tP7h35+nz5JPp0xVbZK6WM0G4G2WAgw\nl13WJ4cgcLek/gk7JiH50UdOEFRz6INsg+oMo3e6LKt/moOwjdhtmZ8gYW9pyKLm\nVhIeUs9tAgMBAAECggEAB19x4HwajlDa2AOBrsTO6LTozKQ/d578IpURXCrDMy8s\n0o1iAPtmue7+qe92vtUJZgBOn43KX8Ic2ekE39rSXNR5MwTPeGCaTAPeVN4RakCh\n3tSiB5oPrUetGQMqNhUPkhT/36BTUzXMnsWHX55J4k5c+R/qaBU9iZiMoNZDogag\nMW6G9qSoJeN4BvqNqR+ICOdTt9dCKHRxkByaUPTwksDsCWHo297U4BPcWsPjgP4Z\nJy4xbdTTOh4Ui7raB2KYd7ID2Js/WQ1fqq06VFU2mJo/2kCldL6f8d71OihPZL+4\nnqoCdg/1mju1kHKOxKye1DR336RGiMEasFnsNgUgAQKBgQDLhwkaqQ/5RO7xOuFE\nfbQ0acklAO7dhXeIomxV9UbdTn+Hct26YBLonSIM3/cYqu0AjJFpu1FrQmIuNBgS\nQcmETar4eiHdB/MhI/p6bB9CaMK2NAsXMnxb4hbTSHR99leLWuGoVE8PQRhhEIQ3\n23b5pyRTUQLFcCtirzOJv/JFQQKBgQC4ZUY0x56KMErpyBW17MVXnjPRPnu7tLsa\nm3ES5tkurD43HB5Hib1GmL6GwbM6sgLSuZMJoKhSsjH7b+px6Fp/ey/ZvwQ1vs3b\nPVHvuFvsp3VtNUKAhxp/OB/OCEkTnLP4Mb2CVfeKejhYZv/8+rqjD4XBjI/knQ9Q\nQfYP1FTjLQKBgQCEAP8spX5QxB7dory8eXNJk1r8fxBt6MTQf9gYIE9n9iPMq/mX\nifx5loChLRnMi//PnVwq4W07TgDzyqHaJYUYJG/BXSVdgGx2kClDAaF8pwmytyqC\nTyJNTeRUAOhdUksRfU5iqNvmHug6/EVlHRibb4al6yMK/2eER/H7Y900gQKBgQCL\nzu2uMvQ33mnOW5BqgX0W87JiIjf6mAuNHvJa3IEq7Bm3+y/SGdNS5Zj/33mfNT0C\nvQWJNTCqksVm2PIvL3b+VU5wkG4GuganBhVL5sJ76nQUO1+Sx90FPG6Q7qNJpXSm\n6D/BxKCNdCGolV/eVdSQscI+f+7R7Wug9II2ek1qeQKBgHg6ODKqZdrD+cxGJ9O7\ntmyrfrcrRJx+sIHJARNegvzilMmwqy85I0JSEfi3uYCsN/s4b5O5s1rSRAw50Di6\nDTa6zmCmBvgE5qVsB4KObzPNAkbkCRJ/BWbBRYs9Ta2x6JcZaM5reiGb+YFWQ7IL\nK/EGIF58hknnXCowedGKKGfR\n-----END PRIVATE KEY-----\n",
    "client_email": "drive-bot@excelproject-455714.iam.gserviceaccount.com",
    "client_id": "115902541194622230230",
    "auth_uri": "https://accounts.google.com/o/oauth2/auth",
    "token_uri": "https://oauth2.googleapis.com/token",
    "auth_provider_x509_cert_url": "https://www.googleapis.com/oauth2/v1/certs",
    "client_x509_cert_url": "https://www.googleapis.com/robot/v1/metadata/x509/drive-bot%40excelproject-455714.iam.gserviceaccount.com",
    "universe_domain": "googleapis.com"
}

SPREADSHEET_ID = "1c3yRBMlcOmzK_g8FWCVD_rztGMXfjsuhF12YVVYNU94"
SCOPES = ["https://www.googleapis.com/auth/spreadsheets"]
creds = ServiceAccountCredentials.from_json_keyfile_dict(CREDENTIALS_DICT, SCOPES)
gc = gspread.authorize(creds)
ws = gc.open_by_key(SPREADSHEET_ID)


def filter_rows_by_seller(data: List[List[str]], seller_id: str) -> List[List[str]]:
    """
    –£–¥–∞–ª—è–µ—Ç –∏–∑ —Å–ø–∏—Å–∫–∞ —Å–ø–∏—Å–∫–æ–≤ –≤—Å–µ —Å—Ç—Ä–æ–∫–∏, —É –∫–æ—Ç–æ—Ä—ã—Ö seller_id –Ω–∞—Ö–æ–¥–∏—Ç—Å—è –≤ 9-–º —Å—Ç–æ–ª–±—Ü–µ (–∏–Ω–¥–µ–∫—Å 8).
    –ü–µ—Ä–≤–∞—è —Å—Ç—Ä–æ–∫–∞ (–∑–∞–≥–æ–ª–æ–≤–∫–∏) —Å–æ—Ö—Ä–∞–Ω—è–µ—Ç—Å—è.

    :param data: –¢–∞–±–ª–∏—Ü–∞ –≤ –≤–∏–¥–µ —Å–ø–∏—Å–∫–∞ —Å–ø–∏—Å–∫–æ–≤
    :param seller_id: ID –ø—Ä–æ–¥–∞–≤—Ü–∞, –∫–æ—Ç–æ—Ä—ã–π –Ω—É–∂–Ω–æ —É–¥–∞–ª–∏—Ç—å
    :return: –ù–æ–≤—ã–π —Å–ø–∏—Å–æ–∫ —Å–ø–∏—Å–∫–æ–≤ –±–µ–∑ —Å—Ç—Ä–æ–∫ —Å —ç—Ç–∏–º seller_id
    """
    if not data:
        return []

    filtered = [row for row in data if len(row) > 8 and row[8] != seller_id]
    return filtered


def convert_dicts_to_rows(data: List[Dict[str, Any]]) -> List[List[Any]]:
    """
    –ü—Ä–µ–æ–±—Ä–∞–∑—É–µ—Ç —Å–ø–∏—Å–æ–∫ —Å–ª–æ–≤–∞—Ä–µ–π –≤ —Å–ø–∏—Å–æ–∫ —Å–ø–∏—Å–∫–æ–≤ —Å –∑–∞–≥–æ–ª–æ–≤–∫–∞–º–∏.

    –ü–æ—Ä—è–¥–æ–∫ –ø–æ–ª–µ–π:
    –ú–∞—Ä–∫–∞(mark), –ì–æ–¥(year), –¶–≤–µ—Ç(color), –ú–æ–¥–µ–ª—å(model),
    –¶–µ–Ω–∞ –±–µ–∑ –Ω–¥—Å(price), –¶–µ–Ω–∞ —Å –Ω–¥—Å(price_with_markup),
    –ê—Ä—Ç–∏–∫—É–ª(id), –°—Å—ã–ª–∫–∞(link), ID –ø—Ä–æ–¥–∞–≤—Ü–∞(seller)
    """
    headers = [
        ("–ú–∞—Ä–∫–∞", "mark"),
        ("–ì–æ–¥", "year"),
        ("–¶–≤–µ—Ç", "color"),
        ("–ú–æ–¥–µ–ª—å", "model"),
        ("–¶–µ–Ω–∞ –±–µ–∑ –ù–î–°", "price"),
        ("–¶–µ–Ω–∞ —Å –ù–î–°", "price_with_markup"),
        ("–ê—Ä—Ç–∏–∫—É–ª", "id"),
        ("–°—Å—ã–ª–∫–∞", "link"),
        ("ID –ø—Ä–æ–¥–∞–≤—Ü–∞", "seller"),
    ]

    result = [[name for name, _ in headers]]  # –∑–∞–≥–æ–ª–æ–≤–∫–∏
    for item in data:
        row = [item.get(key, "") for _, key in headers]
        result.append(row)

    return result


def group_by_mark(data: List[Dict[str, Any]]) -> Dict[str, List[Dict[str, Any]]]:
    """
    –ì—Ä—É–ø–ø–∏—Ä—É–µ—Ç —Å–ø–∏—Å–æ–∫ —Å–ª–æ–≤–∞—Ä–µ–π –ø–æ –∫–ª—é—á—É 'mark'.

    :param data: –°–ø–∏—Å–æ–∫ —Å–ª–æ–≤–∞—Ä–µ–π, –∫–∞–∂–¥—ã–π —Å –∫–ª—é—á–æ–º 'mark'
    :return: –°–ª–æ–≤–∞—Ä—å {–º–∞—Ä–∫–∞: [—Å–ª–æ–≤–∞—Ä—å1, —Å–ª–æ–≤–∞—Ä—å2, ...]}
    """
    grouped: Dict[str, List[Dict[str, Any]]] = {}

    for item in data:
        mark = item.get('mark', 'UNKNOWN')
        grouped.setdefault(mark, []).append(item)

    return grouped


def sheet_exists(spreadsheet: gspread.Spreadsheet, sheet_name: str) -> bool:
    """
    –ü—Ä–æ–≤–µ—Ä—è–µ—Ç, —Å—É—â–µ—Å—Ç–≤—É–µ—Ç –ª–∏ –ª–∏—Å—Ç —Å —Ç–∞–∫–∏–º –Ω–∞–∑–≤–∞–Ω–∏–µ–º –≤ —Ç–∞–±–ª–∏—Ü–µ.

    :param spreadsheet: –û–±—ä–µ–∫—Ç gspread.Spreadsheet
    :param sheet_name: –ù–∞–∑–≤–∞–Ω–∏–µ –ª–∏—Å—Ç–∞
    :return: True, –µ—Å–ª–∏ –ª–∏—Å—Ç —Å—É—â–µ—Å—Ç–≤—É–µ—Ç, –∏–Ω–∞—á–µ False
    """
    return any(ws.title == sheet_name for ws in spreadsheet.worksheets())


def extract_seller_id(url: str) -> Optional[str]:
    """
    –û–ø—Ä–µ–¥–µ–ª—è–µ—Ç seller_id –∏–∑ —Å—Å—ã–ª–∫–∏ Avito –∏–ª–∏ Auto.ru.
    –ï—Å–ª–∏ —Å—Å—ã–ª–∫–∞ –Ω–µ —Ä–∞—Å–ø–æ–∑–Ω–∞–Ω–∞ –∏–ª–∏ –ø–∞—Ä–∞–º–µ—Ç—Ä –Ω–µ –Ω–∞–π–¥–µ–Ω, –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç None.
    """
    parsed = urlparse(url)
    domain = parsed.netloc.lower()

    # Avito: sellerId –≤ query-–ø–∞—Ä–∞–º–µ—Ç—Ä–∞—Ö
    if 'avito.ru' in domain:
        params = parse_qs(parsed.query)
        seller_list = params.get('sellerId') or params.get('sellerid')  # –Ω–∞ –≤—Å—è–∫–∏–π —Å–ª—É—á–∞–π
        return seller_list[0] if seller_list else None

    # Auto.ru: seller_id ‚Äî —á–∞—Å—Ç—å –ø—É—Ç–∏ –ø–æ—Å–ª–µ 'reseller'
    if 'auto.ru' in domain:
        # –ü—Ä–∏–º–µ—Ä –ø—É—Ç–∏: /reseller/3tyBCKbkMS4Uwo1iy0GVpaR1qCiB5CZo/all/...
        parts = parsed.path.strip('/').split('/')
        if 'reseller' in parts:
            idx = parts.index('reseller')
            if idx + 1 < len(parts):
                return parts[idx + 1]
        return None

    # –ù–µ —Ç–æ—Ç –¥–æ–º–µ–Ω
    return None


def safe_get_worksheets(spreadsheet, retries: int = 3, delay: float = 2.0):
    for attempt in range(retries):
        try:
            return spreadsheet.worksheets()
        except Exception as e:
            logger.warning(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ –ø—Ä–∏ –ø–æ–ª—É—á–µ–Ω–∏–∏ —Å–ø–∏—Å–∫–∞ –ª–∏—Å—Ç–æ–≤ (–ø–æ–ø—ã—Ç–∫–∞ {attempt + 1}/{retries}): {e}")
            time.sleep(delay)
    raise RuntimeError("‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ–ª—É—á–∏—Ç—å —Å–ø–∏—Å–æ–∫ –ª–∏—Å—Ç–æ–≤ –ø–æ—Å–ª–µ –Ω–µ—Å–∫–æ–ª—å–∫–∏—Ö –ø–æ–ø—ã—Ç–æ–∫")


def overwrite_sheets(spreadsheet: gspread.Spreadsheet, grouped_data: Dict[str, List[Dict[str, Any]]]) -> None:
    """
    –ü–æ–ª–Ω–æ—Å—Ç—å—é –ø–µ—Ä–µ—Å–æ–∑–¥–∞—ë—Ç –≤—Å–µ –ª–∏—Å—Ç—ã –≤ —Ç–∞–±–ª–∏—Ü–µ, –∫—Ä–æ–º–µ 'Sellers'.
    –ö–∞–∂–¥–æ–π –º–∞—Ä–∫–µ —Å–æ–∑–¥–∞—ë—Ç—Å—è —Å–≤–æ–π –ª–∏—Å—Ç —Å –¥–∞–Ω–Ω—ã–º–∏.
    """
    # 1. –£–¥–∞–ª—è–µ–º –≤—Å–µ –ª–∏—Å—Ç—ã –∫—Ä–æ–º–µ 'Sellers'
    for sheet in safe_get_worksheets(spreadsheet):
        if sheet.title != "Sellers":
            try:
                spreadsheet.del_worksheet(sheet)
                logger.info(f"üóëÔ∏è –£–¥–∞–ª—ë–Ω –ª–∏—Å—Ç: {sheet.title}")
                time.sleep(0.5)  # —á—Ç–æ–±—ã –Ω–µ —É–ø–µ—Ä–µ—Ç—å—Å—è –≤ –∫–≤–æ—Ç—ã
            except Exception as e:
                logger.error(f"‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å —É–¥–∞–ª–∏—Ç—å –ª–∏—Å—Ç '{sheet.title}': {e}", exc_info=True)

    # 2. –°–æ–∑–¥–∞—ë–º –∏ –∑–∞–ø–∏—Å—ã–≤–∞–µ–º –Ω–æ–≤—ã–µ –ª–∏—Å—Ç—ã –ø–æ –º–∞—Ä–∫–∞–º
    for mark, items in grouped_data.items():
        logger.info(f"‚è≥ –°–æ–∑–¥–∞—ë–º –ª–∏—Å—Ç: {mark}")
        rows = convert_dicts_to_rows(items)

        try:
            rows_count = len(rows)
            cols_count = len(rows[0]) if rows else 9
            ws = spreadsheet.add_worksheet(title=mark, rows=str(rows_count), cols=str(cols_count))
            logger.info(f"‚ûï –°–æ–∑–¥–∞–Ω –ª–∏—Å—Ç '{mark}'")
        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ —Å–æ–∑–¥–∞–Ω–∏–∏ –ª–∏—Å—Ç–∞ '{mark}': {e}", exc_info=True)
            continue

        try:
            ws.update('A1', rows)
            logger.info(f"üì§ –î–∞–Ω–Ω—ã–µ –∑–∞–ø–∏—Å–∞–Ω—ã –≤ '{mark}' ‚Äî {len(rows) - 1} —Å—Ç—Ä–æ–∫")
        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –∑–∞–ø–∏—Å–∏ –¥–∞–Ω–Ω—ã—Ö –≤ '{mark}': {e}", exc_info=True)


def get_seller_links(spreadsheet: gspread.Spreadsheet) -> List[str]:
    """
    –û—Ç–∫—Ä—ã–≤–∞–µ—Ç –ª–∏—Å—Ç 'Seller' –∏ –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç –≤—Å–µ –≤–∞–ª–∏–¥–Ω—ã–µ —Å—Å—ã–ª–∫–∏ –∏–∑ –ø–µ—Ä–≤–æ–≥–æ —Å—Ç–æ–ª–±—Ü–∞.

    –£—á–∏—Ç—ã–≤–∞—é—Ç—Å—è —Ç–æ–ª—å–∫–æ —Å—Ç—Ä–æ–∫–∏, –∫–æ—Ç–æ—Ä—ã–µ –Ω–∞—á–∏–Ω–∞—é—Ç—Å—è —Å http –∏–ª–∏ https.

    :param spreadsheet: –æ–±—ä–µ–∫—Ç Google Spreadsheet
    :return: —Å–ø–∏—Å–æ–∫ –≤–∞–ª–∏–¥–Ω—ã—Ö —Å—Å—ã–ª–æ–∫
    """
    try:
        ws = spreadsheet.worksheet("Sellers")
        column_values = ws.col_values(1)  # –ø–µ—Ä–≤—ã–π —Å—Ç–æ–ª–±–µ—Ü (A)

        # –†–µ–≥—É–ª—è—Ä–∫–∞ –Ω–∞ http/https —Å—Å—ã–ª–∫–∏
        url_regex = re.compile(r'^https?://')

        # –í–æ–∑–≤—Ä–∞—â–∞–µ–º —Ç–æ–ª—å–∫–æ —Å—Ç—Ä–æ–∫–∏, –∫–æ—Ç–æ—Ä—ã–µ —è–≤–ª—è—é—Ç—Å—è —Å—Å—ã–ª–∫–∞–º–∏
        return [link.strip() for link in column_values if url_regex.match(link.strip())]

    except gspread.exceptions.WorksheetNotFound:
        logger.error("‚ùå –õ–∏—Å—Ç 'Seller' –Ω–µ –Ω–∞–π–¥–µ–Ω.")
        return []


def run_pipeline(spreadsheet: gspread.Spreadsheet):
    """
    –ì–ª–∞–≤–Ω—ã–π –ø–∞–π–ø–ª–∞–π–Ω: –¥–æ—Å—Ç–∞—ë—Ç —Å—Å—ã–ª–∫–∏ –∏–∑ –ª–∏—Å—Ç–∞ Sellers,
    –ø–∞—Ä—Å–∏—Ç Avito –∏ Auto, –≥—Ä—É–ø–ø–∏—Ä—É–µ—Ç –∏ –∑–∞–ª–∏–≤–∞–µ—Ç –≤ —Ç–∞–±–ª–∏—Ü—É.
    """
    logger.info("üöÄ –ó–∞–ø—É—Å–∫ –ø–∞—Ä—Å–µ—Ä–∞...")
    start = time.time()

    raw_links = get_seller_links(spreadsheet)
    logger.info(f"üîó –ù–∞–π–¥–µ–Ω–æ —Å—Å—ã–ª–æ–∫: {len(raw_links)}")

    auto_links = [link for link in raw_links if 'auto.ru' in link]
    raw_avito_links = [link for link in raw_links if 'avito.ru' in link]

    # –û–±–Ω–æ–≤–ª—è–µ–º —Å—Å—ã–ª–∫–∏ —Å sellerId –¥–ª—è Avito
    logger.info("üß† –û–±–Ω–æ–≤–ª—è–µ–º Avito-—Å—Å—ã–ª–∫–∏ —á–µ—Ä–µ–∑ Playwright...")
    try:
        avito_links = asyncio.run(get_avito_links_with_seller_id(raw_avito_links))
        logger.info(f"üîÑ –û–±–Ω–æ–≤–ª–µ–Ω–æ Avito-—Å—Å—ã–ª–æ–∫: {len(avito_links)}")
    except Exception as e:
        logger.error(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±–Ω–æ–≤–ª–µ–Ω–∏–∏ Avito-—Å—Å—ã–ª–æ–∫: {e}", exc_info=True)
        avito_links = []

    all_data: List[Dict[str, Any]] = []

    # –ü–∞—Ä—Å–∏–Ω–≥ Avito
    for link in avito_links:
        logger.info(f"[Avito] üîç –ü–∞—Ä—Å–∏–º: {link}")
        seller_id = extract_seller_id(link)
        if not seller_id:
            logger.warning(f"[Avito] ‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å –∏–∑–≤–ª–µ—á—å seller_id –∏–∑ {link}")
            continue
        try:
            data = fetch_and_process_items(seller_id)
            all_data.extend(data)
            logger.info(f"[Avito] ‚úÖ –ù–∞–π–¥–µ–Ω–æ –∑–∞–ø–∏—Å–µ–π: {len(data)}")
        except Exception as e:
            logger.error(f"[Avito] ‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –ø–∞—Ä—Å–∏–Ω–≥–µ seller_id={seller_id}: {e}", exc_info=True)

    # –ü–∞—Ä—Å–∏–Ω–≥ Auto.ru
    for link in auto_links:
        logger.info(f"[Auto] üîç –ü–∞—Ä—Å–∏–º: {link}")
        shop_id = extract_seller_id(link)
        if not shop_id:
            logger.warning(f"[Auto] ‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å –∏–∑–≤–ª–µ—á—å shop_id –∏–∑ {link}")
            continue
        try:
            data = parse_auto(shop_id)
            all_data.extend(data)
            logger.info(f"[Auto] ‚úÖ –ù–∞–π–¥–µ–Ω–æ –∑–∞–ø–∏—Å–µ–π: {len(data)}")
        except Exception as e:
            logger.error(f"[Auto] ‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –ø–∞—Ä—Å–∏–Ω–≥–µ shop_id={shop_id}: {e}", exc_info=True)

    if not all_data:
        logger.warning("‚ö†Ô∏è –ù–µ—Ç –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –∑–∞–≥—Ä—É–∑–∫–∏. –ü–∞—Ä—Å–∏–Ω–≥ –∑–∞–≤–µ—Ä—à—ë–Ω –±–µ–∑ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤.")
        return

    logger.info(f"üìä –í—Å–µ–≥–æ –∑–∞–ø–∏—Å–µ–π —Å–æ–±—Ä–∞–Ω–æ: {len(all_data)}")
    grouped_data = group_by_mark(all_data)
    overwrite_sheets(spreadsheet, grouped_data)

    duration = round(time.time() - start, 2)
    logger.info(f"‚úÖ –ì–æ—Ç–æ–≤–æ. –û–±–Ω–æ–≤–ª–µ–Ω–∏–µ –∑–∞–≤–µ—Ä—à–µ–Ω–æ –∑–∞ {duration} —Å–µ–∫.")


if __name__ == '__main__':
    ss = gc.open_by_key(SPREADSHEET_ID)
    run_pipeline(ss)


